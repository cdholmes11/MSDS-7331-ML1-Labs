{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c36cd237",
   "metadata": {},
   "source": [
    "__Title:__ Lab 2: Classificaiton  \n",
    "__Authors:__ Butler, Derner, Holmes  \n",
    "__Date:__ 2/5/23 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "543678d7",
   "metadata": {},
   "source": [
    "## Ruberic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb74a19f",
   "metadata": {},
   "source": [
    "| Category                  | Available | Requirements                                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
    "|---------------------------|-----------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Total Points              | 100       |                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
    "| Data Preparation Part 1   | 10        | Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis.                                                                                                                                                                        |\n",
    "| Data Preparation Part 2   | 5         | Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created).                                                                                                                                                                                                                                                                                          |\n",
    "| Modeling and Evaluation 1 | 10        | Choose and explain your evaluation metrics that you will use (i.e., accuracy, precision, recall, F-measure, or any metric we have discussed). Why are the measure(s) appropriate for analyzing the results of your modeling? Give a detailed explanation backing up any assertions.                                                                                                                                               |\n",
    "| Modeling and Evaluation 2 | 10        | Choose the method you will use for dividing your data into training and testing splits (i.e., are you using Stratified 10-fold cross validation? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate. For example, if you are using time series data then you should be using continuous training and testing sets across time.                                                       |\n",
    "| Modeling and Evaluation 3 | 20        | Create three different classification/regression models for each task (e.g., random forest, KNN, and SVM for task one and the same or different algorithms for task two). Two modeling techniques must be new (but the third could be SVM or logistic regression). Adjust parameters as appropriate to increase generalization performance using your chosen metric. You must investigate different parameters of the algorithms! |\n",
    "| Modeling and Evaluation 4 | 10        | Analyze the results using your chosen method of evaluation. Use visualizations of the results to bolster the analysis. Explain any visuals and analyze why they are interesting to someone that might use this model.                                                                                                                                                                                                             |\n",
    "| Modeling and Evaluation 5 | 10        | Discuss the advantages of each model for each classification task, if any. If there are not advantages, explain why. Is any model better than another? Is the difference significant with 95% confidence? Use proper statistical comparison methods. You must use statistical comparison techniques—be sure they are appropriate for your chosen method of validation as discussed in unit 7 of the course.                       |\n",
    "| Modeling and Evaluation 6 | 10        | Which attributes from your analysis are most important? Use proper methods discussed in class to evaluate the importance of different attributes. Discuss the results and hypothesize about why certain attributes are more important than others for a given classification task.                                                                                                                                                |\n",
    "| Deployment                | 5         | How useful is your model for interested parties (i.e., the companies or organizations that might want to use it for prediction)? How would you measure the model's value if it was used by these parties? How would your deploy your model for interested parties? What other data should be collected? How often would the model need to be updated, etc.?                                                                       |\n",
    "| Exceptional Work          | 10        | You have free reign to provide additional analyses. One idea: grid search parameters in a parallelized fashion and visualize the performances across attributes. Which parameters are most significant for making a good model for each classification algorithm?                                                                                                                                                                 |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b04c1a04",
   "metadata": {},
   "source": [
    "__Libraries & Set-up__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "037a992b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "## Support Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "## Plotting\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "## Model Selection\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "## Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "\n",
    "## Feature Selection\n",
    "from sklearn.feature_selection import SelectFromModel, VarianceThreshold, SelectPercentile\n",
    "\n",
    "## Model Performance\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Notebook Settings\n",
    "warnings.filterwarnings(action='once')\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5277aaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "url = 'https://github.com/cdholmes11/MSDS-7331-ML1-Labs/blob/main/Mini-Lab_LogisticRegression_SVMs/Hotel%20Reservations.csv?raw=true'\n",
    "hotel_df = pd.read_csv(url, encoding = \"utf-8\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e40aba3e",
   "metadata": {},
   "source": [
    "### Data Preparation Part 1\n",
    "Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis.\n",
    "_____________\n",
    "\n",
    "The below dataset updates are the direct result from our dataset analysis done in the previous lab.\n",
    " - [avg_price_per_room] - filtered to under $400 due to lack of observations over this price point and concerns of outlier influence\n",
    " - [no_of_previous_bookings_not_canceled] - dropped due to concerns of outlier influence and because it explains the same observations as [repated_guest]\n",
    " - [Booking_ID] - dropped because it's irrelevant for future predictions\n",
    " - [arrival_year] - dropped because this is not a time series model and thus, it's inclusion would limit our model's potential for classification of arrival years not found in our testing dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3690e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping index column arrival_year\n",
    "hotel_df_trim = hotel_df.drop(['Booking_ID', 'arrival_year', 'no_of_previous_bookings_not_canceled'], axis=1)\n",
    "hotel_df_final = hotel_df_trim.loc[hotel_df_trim['avg_price_per_room'] < 400]\n",
    "\n",
    "# Create data type groups\n",
    "cat_features = ['type_of_meal_plan', 'required_car_parking_space', 'room_type_reserved', 'market_segment_type',\n",
    "    'repeated_guest']\n",
    "int_features = ['no_of_adults', 'no_of_children', 'no_of_weekend_nights', 'no_of_week_nights', 'arrival_month',\n",
    "    'arrival_date', 'no_of_previous_cancellations', 'no_of_special_requests']\n",
    "float_features = ['lead_time', 'avg_price_per_room']\n",
    "cont_features = int_features + float_features\n",
    "\n",
    "# Enforce data types\n",
    "hotel_df_trim[cat_features] = hotel_df_trim[cat_features].astype('category')\n",
    "hotel_df_trim[int_features] = hotel_df_trim[int_features].astype(np.int64)\n",
    "hotel_df_trim[float_features] = hotel_df_trim[float_features].astype(np.float64)\n",
    "\n",
    "# Making indexable list suitable for pipeline\n",
    "cat_features_final = hotel_df_final[cat_features].columns\n",
    "cont_features_final = hotel_df_final[cont_features].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c22ed58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "X = hotel_df_final.drop('booking_status', axis = 1)\n",
    "Y = hotel_df_final['booking_status']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe8f550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline without features selection\n",
    "numeric_features = cont_features_final\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "categorical_features = cat_features_final\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ]\n",
    ")\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "98eea7da",
   "metadata": {},
   "source": [
    "## Example - Remove for Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0180b3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid for GridSearchCV. Will need new one for each model\n",
    "param_grid = {\n",
    "    'classifier__penalty' : ['l1', 'l2', 'elasticnet' ,'none'],\n",
    "    'classifier__C' : [0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'classifier__solver' : ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834f2049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistifc Regression Pipeline\n",
    "clf = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", LogisticRegression(max_iter=1000))]\n",
    ")\n",
    "\n",
    "grid_clf = GridSearchCV(\n",
    "    clf,\n",
    "    param_grid,\n",
    "    verbose=False,\n",
    "    n_jobs=-1,\n",
    "    refit=True,\n",
    "    cv=3\n",
    ")\n",
    "grid_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8a5a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best Parameters:')\n",
    "print(grid_clf.best_params_)\n",
    "\n",
    "print('Internal CV score:')\n",
    "print(grid_clf.best_score_)\n",
    "y_pred_grid = grid_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_grid))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e095640",
   "metadata": {},
   "source": [
    "### Data Preparation Part 2\n",
    "Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created).\n",
    "______\n",
    "\n",
    "__MORE DETAIL IS NEEDED ON WHY THIS IS BEST FOR OUR DATASET__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd1832ea",
   "metadata": {},
   "source": [
    "### Modeling and Evaluation 1\n",
    "Choose and explain your evaluation metrics that you will use (i.e., accuracy, precision, recall, F-measure, or any metric we have discussed). Why are the measure(s) appropriate for analyzing the results of your modeling? Give a detailed explanation backing up any assertions.\n",
    "__________\n",
    "We will be using AUC-ROC to as the primary metric for evaluating our models. This will provide us the optimal true positive and false postive rates for our models. The primary concern of the dataset is understanding the factors that lead to cancellation.\n",
    "\n",
    "__MORE DETAIL IS NEEDED ON WHY THIS IS BEST FOR OUR DATASET__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "55882438",
   "metadata": {},
   "source": [
    "### Modeling and Evaluation 2\n",
    "Choose the method you will use for dividing your data into training and testing splits (i.e., are you using Stratified 10-fold cross validation? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate. For example, if you are using time series data then you should be using continuous training and testing sets across time.\n",
    "______________________\n",
    "We have chosen to use an 80/20 train/test split with 10-fold cross validation. By keeping the 20% hold out and doing 10-fold cross-validation, we further reduce the chances of randomly splitting the data in a facorable way. We effectively get the benefits of 10-fold cross validations and offset the risk by keeping a 20% hold out for final model accuracy testing only. This removes our ability to train on the test set by repeatedly updating our model for better accuracy scores. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4fbb73fd",
   "metadata": {},
   "source": [
    "### Modeling and Evaluation 3\n",
    "Create three different classification/regression models for each task (e.g., random forest, KNN, and SVM for task one and the same or different algorithms for task two). Two modeling techniques must be new (but the third could be SVM or logistic regression). Adjust parameters as appropriate to increase generalization performance using your chosen metric. You must investigate different parameters of the algorithms!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4d880c1f",
   "metadata": {},
   "source": [
    "__KNN__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c4f045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6f275e66",
   "metadata": {},
   "source": [
    "__Decision Trees__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3061aa2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52b46e59",
   "metadata": {},
   "source": [
    "__Random Forest__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80d6fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ade38ef",
   "metadata": {},
   "source": [
    " ### Modeling and Evaluation 4\n",
    " Analyze the results using your chosen method of evaluation. Use visualizations of the results to bolster the analysis. Explain any visuals and analyze why they are interesting to someone that might use this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95388d09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "454ba83b",
   "metadata": {},
   "source": [
    "### Modeling and Evaluation 5\n",
    "Discuss the advantages of each model for each classification task, if any. If there are not advantages, explain why. Is any model better than another? Is the difference significant with 95% confidence? Use proper statistical comparison methods. You must use statistical comparison techniques—be sure they are appropriate for your chosen method of validation as discussed in unit 7 of the course.\n",
    "_____________\n",
    "\n",
    "__MORE DETAIL IS NEEDED ON WHY THIS IS BEST FOR OUR DATASET__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39812d90",
   "metadata": {},
   "source": [
    "### Modeling and Evaluation 6\n",
    "Which attributes from your analysis are most important? Use proper methods discussed in class to evaluate the importance of different attributes. Discuss the results and hypothesize about why certain attributes are more important than others for a given classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b88ed33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f5a8bcc",
   "metadata": {},
   "source": [
    "### Deployment\n",
    "How useful is your model for interested parties (i.e., the companies or organizations that might want to use it for prediction)? How would you measure the model's value if it was used by these parties? How would your deploy your model for interested parties? What other data should be collected? How often would the model need to be updated, etc.?\n",
    "_________\n",
    "__MORE DETAIL IS NEEDED ON WHY THIS IS BEST FOR OUR DATASET__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "87d920b9",
   "metadata": {},
   "source": [
    "### Exceptional Work\n",
    "You have free reign to provide additional analyses. One idea: grid search parameters in a parallelized fashion and visualize the performances across attributes. Which parameters are most significant for making a good model for each classification algorithm?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa3036c9",
   "metadata": {},
   "source": [
    "__Naive Bayes__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39945486",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "77fad8f1fd48b0dbc17e5e0b2f14396946f41876e8f98b3588ed05859c665f39"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
